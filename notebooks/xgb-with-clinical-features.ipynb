{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\ecg\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Anaconda3\\envs\\ecg\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Anaconda3\\envs\\ecg\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Anaconda3\\envs\\ecg\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: llow is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from mtecg.utils import load_ecg_dataframe, categorize_lvef, find_best_thresholds, apply_thresholds\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvef_threshold = 50\n",
    "clinical_feature_columns = [\"female_gender\", \"age\", \"smoke\", \"dlp\", \"dm\", \"ht\"]\n",
    "\n",
    "save_dir = \"../trained_models/xgb\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prepare the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 13343\n",
      "Unique splits: ['old_train' 'old_valid' 'old_test' 'new_train' 'new_valid']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_num</th>\n",
       "      <th>train_80_percent</th>\n",
       "      <th>develop_10_percent</th>\n",
       "      <th>file_name</th>\n",
       "      <th>lvef</th>\n",
       "      <th>scar_cad</th>\n",
       "      <th>hcm</th>\n",
       "      <th>mri_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>dm</th>\n",
       "      <th>ht</th>\n",
       "      <th>mi</th>\n",
       "      <th>pci</th>\n",
       "      <th>cabg</th>\n",
       "      <th>ua</th>\n",
       "      <th>chest pain</th>\n",
       "      <th>dyspnea</th>\n",
       "      <th>path</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009_420521391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2552-08-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...</td>\n",
       "      <td>old_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009_472422791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2552-08-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...</td>\n",
       "      <td>old_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009_451191451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2552-08-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...</td>\n",
       "      <td>old_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009_512029431</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2552-08-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...</td>\n",
       "      <td>old_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009_461543281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2552-08-04 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...</td>\n",
       "      <td>old_train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_num  train_80_percent  develop_10_percent       file_name  lvef  \\\n",
       "0        1               1.0                 NaN  2009_420521391     0   \n",
       "1        2               1.0                 NaN  2009_472422791     0   \n",
       "2        3               1.0                 NaN  2009_451191451     0   \n",
       "3        4               1.0                 NaN  2009_512029431     1   \n",
       "4        5               1.0                 NaN  2009_461543281     1   \n",
       "\n",
       "   scar_cad  hcm             mri_date  month  year  ...  dm  ht  mi  pci  \\\n",
       "0         0    0  2552-08-01 00:00:00      8  2009  ...   0   1   0    0   \n",
       "1         0    0  2552-08-01 00:00:00      8  2009  ...   0   1   0    0   \n",
       "2         0    0  2552-08-01 00:00:00      8  2009  ...   0   1   0    0   \n",
       "3         1    0  2552-08-01 00:00:00      8  2009  ...   1   0   1    1   \n",
       "4         1    0  2552-08-04 00:00:00      8  2009  ...   0   1   0    0   \n",
       "\n",
       "   cabg  ua  chest pain  dyspnea  \\\n",
       "0     0   0           1        0   \n",
       "1     0   0           1        0   \n",
       "2     0   0           1        1   \n",
       "3     0   0           0        1   \n",
       "4     0   0           1        1   \n",
       "\n",
       "                                                path      split  \n",
       "0  ../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...  old_train  \n",
       "1  ../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...  old_train  \n",
       "2  ../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...  old_train  \n",
       "3  ../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...  old_train  \n",
       "4  ../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_i...  old_train  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = \"../../ecg/ecg-cnn-local/siriraj_data/ECG_MRI_images_new/\"\n",
    "csv_path = \"../../ECG_EF_Clin_train_dev_new.csv\"\n",
    "\n",
    "df = load_ecg_dataframe(csv_path, image_dir, drop_impute=False, do_split=True)\n",
    "print(f\"Number of images: {len(df)}\")\n",
    "print(f\"Unique splits: {df['split'].unique()}\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set [\"dm\", \"ht\", \"smoke\", \"dlp\"] to np.nan if \"impute\" is True.\n",
    "df.loc[df[\"impute\"] == True, [\"dm\", \"ht\", \"smoke\", \"dlp\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9393, 28), (2905, 28))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine old train and new train.\n",
    "train_df = df[df.split.isin([\"old_train\", \"new_train\"])].reset_index()\n",
    "# Combine old valid and new valid.\n",
    "valid_df = df[df.split.isin([\"old_valid\", \"new_valid\"])].reset_index()\n",
    "\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dm       0.374580\n",
       "ht       0.747920\n",
       "smoke    0.164985\n",
       "dlp      0.706143\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_impute_train_df = train_df[train_df[\"impute\"] == False]\n",
    "\n",
    "non_impute_train_df[[\"dm\", \"ht\", \"smoke\", \"dlp\"]].sum() / len(non_impute_train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IterativeImputer(random_state=42, sample_posterior=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(random_state=42, sample_posterior=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IterativeImputer(random_state=42, sample_posterior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# imputer = IterativeImputer(\n",
    "#     # estimator=LinearRegression(),\n",
    "#     missing_values=np.nan,\n",
    "#     max_iter=10,\n",
    "#     random_state=42\n",
    "#     )\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    missing_values=np.nan,\n",
    "    max_iter=10,\n",
    "    sample_posterior=True,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "clinical_feature_columns = [\"age\", \"female_gender\", \"dm\", \"ht\", \"smoke\", \"dlp\"]\n",
    "\n",
    "# Fit the imputer on the train set.\n",
    "imputer.fit(train_df[clinical_feature_columns])\n",
    "\n",
    "# Save the imputer.\n",
    "imputer_path = op.join(save_dir, \"imputer.joblib\")\n",
    "joblib.dump(imputer, imputer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the train set.\n",
    "train_df[clinical_feature_columns] = imputer.transform(train_df[clinical_feature_columns])\n",
    "\n",
    "# Impute missing values in the valid set.\n",
    "valid_df[clinical_feature_columns] = imputer.transform(valid_df[clinical_feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dm': [0.54, 0.0033188878449101344],\n",
       " 'ht': [0.42, 0.001278732110516545],\n",
       " 'smoke': [0.52, 0.003125978730067952],\n",
       " 'dlp': [0.44, 0.0027248412471461148]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best thresholds for imputing missing values from the train set.\n",
    "best_threshold_dict = find_best_thresholds(train_df)\n",
    "\n",
    "joblib.dump(best_threshold_dict, op.join(save_dir, \"imputer_threshold_dict.joblib\"))\n",
    "\n",
    "# Apply the best thresholds to the train set and the valid set.\n",
    "train_df = apply_thresholds(train_df, best_threshold_dict)\n",
    "valid_df = apply_thresholds(valid_df, best_threshold_dict)\n",
    "\n",
    "best_threshold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dm       0.373257\n",
       "ht       0.748430\n",
       "smoke    0.163739\n",
       "dlp      0.707229\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"dm\", \"ht\", \"smoke\", \"dlp\"]].sum() / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[clinical_feature_columns]\n",
    "x_valid = valid_df[clinical_feature_columns]\n",
    "\n",
    "y_train_scar = train_df[\"scar_cad\"]\n",
    "y_valid_scar = valid_df[\"scar_cad\"]\n",
    "y_train_lvef = train_df[\"lvef\"]\n",
    "y_valid_lvef = valid_df[\"lvef\"]\n",
    "# y_train_lvef = train_df[\"lvef\"].apply(lambda lvef: categorize_lvef(lvef, lvef_threshold))\n",
    "# y_valid_lvef = valid_df[\"lvef\"].apply(lambda lvef: categorize_lvef(lvef, lvef_threshold))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scar_model = XGBClassifier(\n",
    "    booster=\"dart\",\n",
    "    tree_method=\"hist\",\n",
    "    grow_policy=\"lossguide\",\n",
    "    sample_type=\"weighted\",\n",
    "    sampling_method=\"gradient_based\",\n",
    "    normalize_type=\"forest\",\n",
    "    rate_drop=0.3,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "lvef_model = XGBClassifier(\n",
    "    booster=\"dart\",\n",
    "    tree_method=\"hist\",\n",
    "    grow_policy=\"lossguide\",\n",
    "    sample_type=\"weighted\",\n",
    "    sampling_method=\"gradient_based\",\n",
    "    normalize_type=\"forest\",\n",
    "    rate_drop=0.3,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scar accuracy: 0.7432013769363167\n",
      "LVEF accuracy: 0.8292598967297763\n"
     ]
    }
   ],
   "source": [
    "scar_model.fit(x_train, y_train_scar)\n",
    "print(\"Scar accuracy:\", scar_model.score(x_valid, y_valid_scar))\n",
    "\n",
    "lvef_model.fit(x_train, y_train_lvef)\n",
    "print(\"LVEF accuracy:\", lvef_model.score(x_valid, y_valid_lvef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scar AUC: 0.659479405034325\n",
      "LVEF AUC: 0.6177557760803911\n"
     ]
    }
   ],
   "source": [
    "print(\"Scar AUC:\", roc_auc_score(y_valid_scar, scar_model.predict_proba(x_valid)[:, 1]))\n",
    "print(\"LVEF AUC:\", roc_auc_score(y_valid_lvef, lvef_model.predict_proba(x_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../trained_models/xgb\\\\lvef_model\\\\model.joblib']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "scar_model_save_dir = op.join(save_dir, \"scar_model\")\n",
    "lvef_model_save_dir = op.join(save_dir, \"lvef_model\")\n",
    "os.makedirs(scar_model_save_dir, exist_ok=True)\n",
    "os.makedirs(lvef_model_save_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(scar_model, op.join(scar_model_save_dir, \"model.joblib\"))\n",
    "joblib.dump(lvef_model, op.join(lvef_model_save_dir, \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get XGBoost predictions.\n",
    "from mtecg.evaluation import calculate_metrics_per_task\n",
    "\n",
    "\n",
    "def evaluate_xgb_from_dataframe(\n",
    "    dataframe: pd.DataFrame,\n",
    "    model: XGBClassifier,\n",
    "    feature_columns: List[str],\n",
    "    label_column_name: str = \"scar_cad\",\n",
    "    task=\"scar\",\n",
    "    ):\n",
    "    x = dataframe[feature_columns]\n",
    "    predicted_probability_array = model.predict_proba(x)[:, 1]\n",
    "    prediction_array = model.predict(x)\n",
    "\n",
    "    prediction_dataframe = pd.DataFrame(\n",
    "        {\n",
    "            f\"{task}_label\": dataframe[label_column_name].values,\n",
    "            f\"{task}_prediction\": prediction_array,\n",
    "            f\"{task}_probability\": predicted_probability_array,\n",
    "        }\n",
    "    )\n",
    "    metrics_dataframe = calculate_metrics_per_task(prediction_dataframe, task)\n",
    "    return prediction_dataframe, metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scar_prediction_df, scar_metric_df = evaluate_xgb_from_dataframe(valid_df, scar_model, clinical_feature_columns, task=\"scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvef_prediction_df, lvef_metric_df = evaluate_xgb_from_dataframe(valid_df, lvef_model, clinical_feature_columns, task=\"lvef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_per_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "109b74d06ceef90c267188b655f808679842e5df9d924ed4ca45afc3047e2ff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
